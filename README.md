# ğŸš€ Universal Low Latency Runbook

This project helps developers **analyze code snippets** for potential **latency bottlenecks** using:
- A rule-based **static analyzer**
- An optional LLM-powered **GPT reviewer** via **OpenRouter.ai**

Built with â¤ï¸ by [Gauri Bhardwaj](https://github.com/gauribhardwaj)

---

## ğŸ“¸ Demo
![screenshot](https://github.com/gauribhardwaj/Low-Latency-101/assets/demo.png)

---

## ğŸ“‚ Project Structure

```
Low-Latency-101/
â”‚
â”œâ”€â”€ app.py                            # ğŸ”µ Main Streamlit UI
â”œâ”€â”€ .env                              # ğŸ” Your API key (not checked in)
â”œâ”€â”€ latency_engine/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ gpt_review.py                 # ğŸ¤– GPT LLM handler
â”‚   â””â”€â”€ latency_analyzer.py          # ğŸ§  Rule-based static analysis engine
â”‚
â”œâ”€â”€ latency_engine/rules/
â”‚   â”œâ”€â”€ python_rules.json
â”‚   â”œâ”€â”€ java_rules.json
â”‚   â””â”€â”€ cpp_rules.json               # ğŸ” Language-specific rules
â”‚
â”œâ”€â”€ requirements.txt                 # ğŸ“¦ Python dependencies
â””â”€â”€ README.md                        # ğŸ“˜ You're here!
```

---

## ğŸ’» Run Locally

### âœ… 1. Clone the repo

```bash
git clone https://github.com/gauribhardwaj/Low-Latency-101.git
cd Low-Latency-101
```

### âœ… 2. Create a virtual environment (optional but recommended)

```bash
python -m venv venv
source venv/bin/activate       # On Mac/Linux
venv\Scripts\activate        # On Windows
```

### âœ… 3. Install Python dependencies

```bash
pip install -r requirements.txt
```

### âœ… 4. Get OpenRouter API Key

1. Go to [https://openrouter.ai](https://openrouter.ai)
2. Login â†’ Get your **API key** (starts with `sk-or-...`)
3. Copy it.

Create a `.env` file in the project root:

```env
OPENROUTER_API_KEY=sk-or-your-api-key-here
```

> âš ï¸ This file should **not be committed**. It's already added in `.gitignore`.

### âœ… 5. Run the app

```bash
streamlit run app.py
```

### âœ… 6. Use the UI

1. Select the language: `Python`, `Java`, or `C++`
2. Paste your code snippet
3. Click **"Analyze Code"** to run the static engine
4. (Optional) Tick âœ… the **GPT Review** checkbox to get suggestions from DeepSeek (via OpenRouter)

---

## ğŸ§  Sample Code (Python)

```python
for i in range(10000):
    print("Iteration", i)
    result = [x * x for x in range(1000)]
```

**Static Output**:
- âŒ I/O in hot loop
- âŒ List allocations per iteration
- Score: 70/100

**GPT Output** (DeepSeek):
- Use generator expressions
- Cache function calls
- Buffer print statements

---

## ğŸ§° Dependencies

- `streamlit`
- `requests`
- `dotenv`
- `re`, `json`, `os`, `logging`

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ“¡ Optional: Deploy to Streamlit Cloud

1. Push this repo to GitHub
2. Go to [streamlit.io/cloud](https://streamlit.io/cloud) and deploy it
3. Add your `OPENROUTER_API_KEY` as a **secret**

---

## ğŸ“¬ Contact

For feedback or collaborations, reach out on [LinkedIn](https://www.linkedin.com/in/gauribhardwaj7) or file an issue.

---

## ğŸ›¡ï¸ License

MIT License Â© [gauribhardwaj](https://github.com/gauribhardwaj)
